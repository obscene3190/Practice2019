# Practice2019. Блинов А.С.

## 1. Что такое регуляризация в машинном обучении?

Регуляризация - это техника, которая позволяет избежать переобучения нейросети во время обучения, даже если данных мало. Признак переобучившейся нейросети - большие значения весов порядка сотен и тысяч; такая нейросеть не будет нормально работать на новых данных. [1.1]
Простейший метод регуляризации называется ранней остановкой. Он состоит, как следует из названия, в том, чтобы остановить обучение, как только ошибка проверки достигает минимальной ошибки.
Распад веса является еще одним очень распространенным методом регуляризации. Он используется для ограничения значений больших весов. Эти методы обычно реализуются путем добавления дополнительных условий для функций сети. В регуляризации L2 к функции стоимости добавляется дополнительный член, который штрафует квадратную величину всех параметров. <…>
Другой общей регуляризацией распада веса является регуляризация L1 , которая создает разреженные ограничения на вес. Подобно L2 , регуляризация L1 включает в себя дополнительный термин к стоимости <…> [1.2]

## 2. Что такое глубокая сеть доверия (deep belief networks)?

Глубокая сеть доверия — это название, которое получил тип архитектуры, в которой сеть состоит из нескольких соединённых ограниченных машин Больцмана или вариационных автокодировщиков. Такие сети обучаются поблочно, причём каждому блоку требуется лишь уметь закодировать предыдущий. Такая техника называется «жадным обучением», 69 которая заключается в выборе локальных оптимальных решений, не гарантирующих оптимальный конечный результат. Также сеть можно обучить (методом обратного распространения ошибки) отображать данные в виде вероятностной модели. Если использовать обучение без учителя, стабилизированную модель можно использовать для генерации новых данных.
<…>
ГСД можно рассматривать как композицию простых, спонтанных сетей, таких как ограниченные машины Больцмана (ОМБ) или автокодировщики, в которой скрытый слой каждой подсети служит видимым слоем для следующей. Это позволяет осуществить быструю послойную процедуру обучения без учителя, в которой относительное расхождение применяется к каждой подсети по очереди, начиная с первой пары слоев (на видимый слой которой подается тренировочный набор примеров). [2.1]

Deep belief nets are probabilistic generative models that are composed of multiple layers of stochastic latent variables (also called “feature detectors” or “hidden units”). The top two layers have undirected, symmetric connections between them and form an associative memory. The lower layers receive top-down, directed connections from the layer above. Deep belief nets have two important computational properties. First, there is an efficient procedure for learning the topdown, generative weights that specify how the variables in one layer determine the probabilities of variables in the layer below. This procedure learns one layer of latent variables at a time. Second, after learning multiple layers, the values of the latent variables in every layer can be inferred by a single, bottom-up pass that starts with an observed data vector in the bottom layer and uses the generative weights in the reverse direction. [2.2]

## 3. Что такое метод Монте-Карло?

<…> В тех случаях, когда требуется более адекватное суждение о случайном поведении оцениваемой величины, в науке используют иной подход, в основе которого лежит метод статистических испытаний, или метод Монте-Карло.
Идея метода Монте-Карло состоит в последовательной генерации значений наборов случайных величин, входящих в исследуемую зависимость<…>. Полученная комбинация значений используется для вычисления одиночного значения функции по этой формуле, которое является результатом данного «статистического испытания». Многократное повторение таких испытаний позволяет получить массив значений этой случайной величины, статистическая обработка которого дает значение интегральной функции распределения, т. е. полностью описывает данную случайную величину.
Основным исполнительным механизмом метода Монте-Карло является генерация значений случайной величины по заданному закону ее распределения, что обычно выполняется с помощью метода обратной функции. [3]

## 4. В каких задачах информационной безопасности применяют машинное обучение.

В настоящее время существует множество технических решений по обеспечению безопасности информации при ее обработке в информационной системе. Одним из таких решений являются системы управления информационной безопасностью (СУИБ). СУИБ начали получать активное распространение примерно с 2012 г., во время динамичного развития технологий аналитической работы с большими объемами данных и машинного обучения. Одним из направлений развития СУИБ стала разработка систем анализа поведения пользователей (САПП). В задачи САПП входит анализ действий пользователей (состав обрабатываемых данных, контроль используемых устройств и приложений, учет взаимодействий с другими пользователями и т. п.) и выявление аномалий в их поведении. В общем случае в ходе работы САПП каждому пользователю присваивается определенный уровень надежности, отражающий общую адекватность его поведения в удобном для восприятия администратором безопасности виде.
Примерами практического применения САПП являются выявление аномальных действий, совершаемых от имени: — служебных учетных записей (например, использование учетных записей, предназначенных для обеспечения определенных сервисов, в иных целях); — привилегированных учетных записей (администратор домена осуществляет массовый сбор рабочих материалов пользователей и т. п.); — учетных записей обычных пользователей (активный анализ доступных сетевых ресурсов, доступ в несвойственное для пользователя время или из несвойственного места, параллельный доступ из нескольких мест, резко возросшие объемы исходящего в Интернет трафика и т. п.). Выявление аномалий, распределенных во времени или среди нескольких пользователей, как правило, затруднительно, если оно основано на применении экспертных систем, и требует значительных временных и вычислительных ресурсов. Из-за большого разнообразия действий пользователей даже регулярные обновления базы данных правил экспертной системы не способны гарантировать точной идентификации всего диапазона аномалий. Одним из подходов к устранению указанных затруднений может быть использование в составе САПП интеллектуальных подсистем, разработанных с помощью методик машинного обучения.
Машинное обучение является одним из направлений развития искусственного интеллекта и за счет применения различных математических аппаратов (таких как математическая статистика, теория вероятностей, численные методы оптимизации и т. п.) позволяет решать задачи классификации, кластеризации, систематизации, предсказания и регрессии. В направлении машинного обучения можно выделить искусственные нейронные сети (ИНС).
Универсальность, которая изначально была заложена в ИНС, обусловливает активное развитие этого направления как в целом, так и в области обеспечения информационной безопасности: при защите от сетевых атак и вторжений, антивирусной защите, фильтрации спама, анализе безопасности, анализе угроз, разработке адаптивных средств защиты, выявлении аномалий и пр. [4]

## 5. Назовите любой недостаток применения машинного обучения в информационной безопасности.

While machine learning has widely been used in system defense applications, machine learning models impose security risks, which are described as follows: – As shown in Section 3, machine learning can be used by adversaries to launch attacks. – The results in Tables 1–6 show that in most of the reviewed papers, accuracy is not equal to 100%, which means that there are still incorrectly classified data points in the test set. Moreover, even if the reported accuracy is 100% based on a specific test set, it is not guaranteed that the accuracy will be 100% in practical situation. When machine learning is applied in realistic scenarios, mis-classification of a single attack is enough to exploit the whole system. –
Defense mechanisms based on machine learning can be tampered with; attackers can launch attacks on the machine learning models themselves. Attackers can mislead classification process by injecting attacks that are deliberately classified as safe while they are in fact malicious.
While machine learning is a promising approach for hardware security, if the detection accuracy and the true positive rate are not 100%, the system is under severe security risk. Therefore, we recommend that when machine learning models are deployed in security related applications, only the detected attacks are taken into consideration, however, instances that are marked as normal should be treated as suspicious, i.e., these instances may be misclassified as normal while they are in fact attacks. [5]
 
## Список источников:

[1.1] Пеньков Илья Андреевич. Реализация нейросетевой модели для краткосрочного прогнозированияпоказателей инвестиций. Анализ и современные информационные технологии в обеспечении экономической безопасности бизнеса и государства
Сборник научных трудов и результатов совместных научно-исследовательских проектов. РЭУ им. Г.В. Плеханова. Москва, 2016 Стр. 521-527.

[1.2] Каунг Мьят Сан, Абрамов Ю.А., Гинзгеймер С.А. Свёрточные нейронные сети в задачах глубокого обучения. Международный студенческий научный вестник. 2018. № 5. Страница: 153.

[2.1] Лазарев А.С., Пивоваров С.А., Журба А.К. Глубокая сеть доверия.
Современные концепции развития науки. Сборник статей Международной научно-практической конференции. 2017. Страница: 68-70.

[2.2] Claude Sammut, Geoffrey I. Webb. Encyclopedia of Machine Learning and Data Mining. 2017. P. 335 DOI: 10.1007/978-1-4899-7687-1

[3] Валькова Светлана Сергеевна. Вероятностно-статистический метод расчета вместимости склада морского порта.
Вестник государственного университета морского и речного флота им. адмирала С.О. Макарова. 2018. Номер 3. Том 10. Страница: 507-519.

[4] Козин Иван Сергеевич. Метод обеспечения безопасности персональных данных при их обработке в информационной системе на основе анализа поведения пользователей.
Журнал информационно-управляющие системы. 2018. Номер 3(94). Страница: 69-78.

[5] Rana Elnaggar, Krishnendu Chakrabarty. Machine Learning for Hardware Security: Opportunities and Risks. Journal of Electronic Testing. 2018. Volume 34, Issue 2, pp 183–201. DOI:10.1007/s10836-018-5726-9
